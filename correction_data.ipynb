{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from algorithms.functions_langs.comparison_laguagues_celexes_docs import comparison_laguagues_celexes_docs\n",
    "from algorithms.functions_langs.creation_df_langugues import creation_df_langugues\n",
    "from algorithms.functions_try.functions_try_collection import try_except_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celexes_0 = []\n",
    "docs_0 = []\n",
    "\n",
    "with open('./files/txts/data/celex_to_text_part_0.txt', encoding=\"utf8\") as file:\n",
    "    for celex in file:\n",
    "        try:\n",
    "            celexes_0.append(celex.split(':')[0])\n",
    "            docs_0.append(' '.join(celex.split(':')[1:]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "celexes_1 = []\n",
    "docs_1 = []\n",
    "with open(f'./files/txts/data/celex_to_text_part_1.txt', encoding=\"utf8\") as file:\n",
    "    for celex in file:\n",
    "        try:\n",
    "            celexes_1.append(celex.split(':')[0])\n",
    "            docs_1.append(' '.join(celex.split(':')[1:]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "celexes_2 = []\n",
    "docs_2 = []\n",
    "with open(f'./files/txts/data/celex_to_text_part_2.txt', encoding=\"utf8\") as file:\n",
    "    for celex in file:\n",
    "        try:\n",
    "            celexes_2.append(celex.split(':')[0])\n",
    "            docs_2.append(' '.join(celex.split(':')[1:]))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "celexes_3 = []\n",
    "docs_3 = []\n",
    "with open(f'./files/txts/data/celex_to_text_part_3.txt', encoding=\"utf8\") as file:\n",
    "    for celex in file:\n",
    "        try:\n",
    "            celexes_3.append(celex.split(':')[0])\n",
    "            docs_3.append(' '.join(celex.split(':')[1:]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "celexes_4 = []\n",
    "docs_4 = []\n",
    "with open(f'./files/txts/data/celex_to_text_part_4.txt', encoding=\"utf8\") as file:\n",
    "    for celex in file:\n",
    "        try:\n",
    "            celexes_4.append(celex.split(':')[0])\n",
    "            docs_4.append(' '.join(celex.split(':')[1:]))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.DataFrame([celexes_0, docs_0]).T\n",
    "df_1 = pd.DataFrame([celexes_1, docs_1]).T\n",
    "df_2 = pd.DataFrame([celexes_2, docs_2]).T\n",
    "df_3 = pd.DataFrame([celexes_3, docs_3]).T\n",
    "df_4 = pd.DataFrame([celexes_4, docs_4]).T\n",
    "\n",
    "df_0.columns = ['CELEX_ID', 'DOC_CONTENT']\n",
    "df_1.columns = ['CELEX_ID', 'DOC_CONTENT']\n",
    "df_2.columns = ['CELEX_ID', 'DOC_CONTENT']\n",
    "df_3.columns = ['CELEX_ID', 'DOC_CONTENT']\n",
    "df_4.columns = ['CELEX_ID', 'DOC_CONTENT']\n",
    "\n",
    "df_0 = df_0[(df_0['DOC_CONTENT'] != \" '{',\\n\") & ~(df_0['CELEX_ID'].str.contains(\"\\n\"))]\n",
    "df_1 = df_1[(df_1['DOC_CONTENT'] != \" '{',\\n\") & ~(df_1['CELEX_ID'].str.contains(\"\\n\"))]\n",
    "df_2 = df_2[(df_2['DOC_CONTENT'] != \" '{',\\n\") & ~(df_2['CELEX_ID'].str.contains(\"\\n\"))]\n",
    "df_3 = df_3[(df_3['DOC_CONTENT'] != \" '{',\\n\") & ~(df_3['CELEX_ID'].str.contains(\"\\n\"))]\n",
    "df_4 = df_4[(df_4['DOC_CONTENT'] != \" '{',\\n\") & ~(df_4['CELEX_ID'].str.contains(\"\\n\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_langs_0 = creation_df_langugues(df_0)\n",
    "df_langs_1 = creation_df_langugues(df_1)\n",
    "df_langs_2 = creation_df_langugues(df_2)\n",
    "df_langs_3 = creation_df_langugues(df_3)\n",
    "df_langs_4 = creation_df_langugues(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_indexes_false_comparison_0 = comparison_laguagues_celexes_docs(df_0, df_langs_0)\n",
    "list_of_indexes_false_comparison_1 = comparison_laguagues_celexes_docs(df_1, df_langs_1)\n",
    "list_of_indexes_false_comparison_2 = comparison_laguagues_celexes_docs(df_2, df_langs_2)\n",
    "list_of_indexes_false_comparison_3 = comparison_laguagues_celexes_docs(df_3, df_langs_3)\n",
    "list_of_indexes_false_comparison_4 = comparison_laguagues_celexes_docs(df_4, df_langs_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = pd.concat([df[df['CELEX_ID'].str.contains('EN') \n",
    "                        & ~(df.index.isin(indexes_for_exclude))\n",
    "                        & ~(df['DOC_CONTENT'].str.contains('/C'))\n",
    "                        & ~(df['DOC_CONTENT'].str.contains('. . . . . . '))] \n",
    "                    for df, indexes_for_exclude in zip(\n",
    "                        [\n",
    "                            df_0, \n",
    "                            df_1, \n",
    "                            df_2, \n",
    "                            df_3, \n",
    "                            df_4,\n",
    "                        ], \n",
    "                        [   list_of_indexes_false_comparison_0,\n",
    "                            list_of_indexes_false_comparison_1,\n",
    "                            list_of_indexes_false_comparison_2, \n",
    "                            list_of_indexes_false_comparison_3, \n",
    "                            list_of_indexes_false_comparison_4,\n",
    "                        ])\n",
    "                    ])\n",
    "df_en['DOC_CONTENT'] = df_en['DOC_CONTENT'].apply(lambda x: re.sub(\"^\\s+|\\n|\\r|\\s+$\", ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en['CELEX_ID_FULL'] = df_en['CELEX_ID']\n",
    "df_en['CELEX_ID'] = df_en['CELEX_ID'].apply(lambda x: x.split('_')[1])\n",
    "df_en['LANG'] = df_en['CELEX_ID_FULL'].apply(lambda x: try_except_get(x.split('_'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_of_general_celexes = pd.read_csv('celexes_general.csv')\n",
    "frame_of_general_celexes['Directory code'] = frame_of_general_celexes['Directory code'].astype(str)\n",
    "frame_of_general_celexes['Directory code'] += ', '\n",
    "frame_of_general_celexes = frame_of_general_celexes.groupby('0')['Directory code'].agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_of_general_celexes.columns = ['CELEX_ID', 'Directory code']\n",
    "frame_all_en = frame_of_general_celexes.merge(df_en)\n",
    "frame_all_en.to_excel('full_en_data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
